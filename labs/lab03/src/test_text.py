import lib.text as form
# Test for normilize
print('\nTesting normilize func\n')
print(r'–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t  Out: ', form.normalize('–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t'))
print(r'—ë–∂–∏–∫, –Å–ª–∫–∞  Out: ', form.normalize('—ë–∂–∏–∫, –Å–ª–∫–∞', yo2e=True))
print(r'Hello\r\nWorld  Out: ', form.normalize('Hello\r\nWorld'))
print(r' –¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã   Out: ', form.normalize(' –¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã '))

# Tests for tokenize
print('\nTesting tokenize func\n')
print(r'–ø—Ä–∏–≤–µ—Ç –º–∏—Ä Out:', form.tokenize('–ø—Ä–∏–≤–µ—Ç –º–∏—Ä'))
print(r'hello,world!!! Out:', form.tokenize('hello,world!!!'))
print(r'–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ Out:', form.tokenize('–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ'))
print(r'2025 –≥–æ–¥ Out:', form.tokenize('2025 –≥–æ–¥'))
print(r'emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ Out:', form.tokenize('emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ'))

# Tests for count and top
print('\nTesting count_freq & top_n\n')
print(f'["a","b","a","c","b","a"] Out counter: {form.count_freq(["a","b","a","c","b","a"])} Out top_n {form.top_n(form.count_freq(["a","b","a","c","b","a"]))}')
print(f'["bb","aa","bb","aa","cc"] Out counter: {form.count_freq(["bb","aa","bb","aa","cc"])} Out top_n {form.top_n(form.count_freq(["bb","aa","bb","aa","cc"]), 2)}')

